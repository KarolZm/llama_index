{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d89b5c",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/node_postprocessor/ibm_watsonx_rerank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70996d8a",
   "metadata": {},
   "source": [
    "# IBM watsonx.ai\n",
    "\n",
    ">WatsonxRerank is a wrapper for IBM [watsonx.ai](https://www.ibm.com/products/watsonx-ai) Rerank.\n",
    "\n",
    "The aim of these examples is to show how to take advantage of `watsonx.ai` Embeddings, LLMs and Rerank using the `LlamaIndex` postprocessor API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea35b2b7",
   "metadata": {},
   "source": [
    "## Setting up\n",
    "\n",
    "Install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU llama-index-llms-ibm\n",
    "%pip install -qU llama-index-postprocessor-ibm-rerank\n",
    "%pip install -qU llama-index-embeddings-ibm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f406e092",
   "metadata": {},
   "source": [
    "The cell below defines the credentials required to work with watsonx Foundation Models, Embeddings and Rerank.\n",
    "\n",
    "**Action:** Provide the IBM Cloud user API key. For details, see\n",
    "[Managing user API keys](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d572a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "watsonx_api_key = getpass()\n",
    "os.environ[\"WATSONX_APIKEY\"] = watsonx_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59782a7",
   "metadata": {},
   "source": [
    "Additionally, you can pass additional secrets as an environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WATSONX_URL\"] = \"your service instance url\"\n",
    "os.environ[\"WATSONX_TOKEN\"] = \"your token for accessing the CPD cluster\"\n",
    "os.environ[\"WATSONX_PASSWORD\"] = \"your password for accessing the CPD cluster\"\n",
    "os.environ[\"WATSONX_USERNAME\"] = \"your username for accessing the CPD cluster\"\n",
    "os.environ[\n",
    "    \"WATSONX_INSTANCE_ID\"\n",
    "] = \"your instance_id for accessing the CPD cluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de9336",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "\n",
    "- To provide context for the API call, you must pass the `project_id` or `space_id`. To get your project or space ID, open your project or space, go to the **Manage** tab, and click **General**. For more information see: [Project documentation](https://www.ibm.com/docs/en/watsonx-as-a-service?topic=projects) or [Deployment space documentation](https://www.ibm.com/docs/en/watsonx/saas?topic=spaces-creating-deployment).\n",
    "- Depending on the region of your provisioned service instance, use one of the urls listed in [watsonx.ai API Authentication](https://ibm.github.io/watsonx-ai-python-sdk/setup_cloud.html#authentication).\n",
    "\n",
    "In this example, weâ€™ll use the `project_id` and Dallas URL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef7659",
   "metadata": {},
   "source": [
    "Provide `PROJECT_ID` that will be used for initialize each watsonx integration instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"PASTE YOUR PROJECT_ID HERE\"\n",
    "URL = \"https://us-south.ml.cloud.ibm.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0308874",
   "metadata": {},
   "source": [
    "## Download data and load documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de18e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65dc946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106479c9",
   "metadata": {},
   "source": [
    "## Load the embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b86b6b",
   "metadata": {},
   "source": [
    "#### Initialize the `WatsonxEmbeddings` instance.\n",
    "\n",
    ">For more information about `WatsonxEmbeddings` please refer to the sample notebook: <a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/embeddings/ibm_watsonx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bf6aaf",
   "metadata": {},
   "source": [
    "You might need to adjust embedding parameters for different tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate_input_tokens = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.ibm import WatsonxEmbeddings\n",
    "\n",
    "watsonx_embedding = WatsonxEmbeddings(\n",
    "    model_id=\"ibm/slate-125m-english-rtrvr\",\n",
    "    url=URL,\n",
    "    project_id=PROJECT_ID,\n",
    "    truncate_input_tokens=truncate_input_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a5570f",
   "metadata": {},
   "source": [
    "#### Build index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb518f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=documents, embed_model=watsonx_embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3270b3a3",
   "metadata": {},
   "source": [
    "## Load the Rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc82133",
   "metadata": {},
   "source": [
    "You might need to adjust rerank parameters for different tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d98419",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate_input_tokens = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de918919",
   "metadata": {},
   "source": [
    "#### Initialize `WatsonxRerank` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a3c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.ibm_rerank import WatsonxRerank\n",
    "\n",
    "watsonx_rerank = WatsonxRerank(\n",
    "    model_id=\"cross-encoder/ms-marco-minilm-l-12-v2\",\n",
    "    top_n=2,\n",
    "    url=URL,\n",
    "    project_id=PROJECT_ID,\n",
    "    truncate_input_tokens=truncate_input_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d107fe",
   "metadata": {},
   "source": [
    "Alternatively, you can use Cloud Pak for Data credentials. For details, see [watsonx.ai software setup](https://ibm.github.io/watsonx-ai-python-sdk/setup_cpd.html).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.ibm_rerank import WatsonxRerank\n",
    "\n",
    "watsonx_rerank = WatsonxRerank(\n",
    "    model_id=\"cross-encoder/ms-marco-minilm-l-12-v2\",\n",
    "    url=URL,\n",
    "    username=\"PASTE YOUR USERNAME HERE\",\n",
    "    password=\"PASTE YOUR PASSWORD HERE\",\n",
    "    instance_id=\"openshift\",\n",
    "    version=\"5.1\",\n",
    "    project_id=PROJECT_ID,\n",
    "    truncate_input_tokens=truncate_input_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36acbef",
   "metadata": {},
   "source": [
    "## Load the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2924c37",
   "metadata": {},
   "source": [
    "#### Initialize the `WatsonxLLM` instance.\n",
    "\n",
    ">For more information about `WatsonxLLM` please refer to the sample notebook: <a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/llm/ibm_watsonx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359898de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ibm import WatsonxLLM\n",
    "\n",
    "watsonx_llm = WatsonxLLM(\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
    "    url=URL,\n",
    "    project_id=PROJECT_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be7fc6c",
   "metadata": {},
   "source": [
    "## Retrieve top 10 most relevant nodes, then filter with `WatsonxRerank`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84f0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    llm=watsonx_llm,\n",
    "    similarity_top_k=10,\n",
    "    node_postprocessors=[watsonx_rerank],\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"What did Sam Altman do in this essay?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "\n",
    "pprint_response(response, show_source=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf5df0b",
   "metadata": {},
   "source": [
    "#### Directly retrieve top 2 most similar nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f784254",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    llm=watsonx_llm,\n",
    "    similarity_top_k=2,\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"What did Sam Altman do in this essay?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8163a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint_response(response, show_source=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
